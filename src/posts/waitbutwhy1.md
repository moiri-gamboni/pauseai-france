---
title: Wait But Why - IA - Partie 1
description: Partie 1
date: '20254-04-02'
layout: waitbutwhy
---

# La Révolution de l'IA : La Route vers la Superintelligence

**22 janvier 2015 Par Tim Urban – traduction de Février 2025**

Note : _Si ce billet m'a pris trois semaines à finir, c'est qu'en fouillant dans mes recherches sur l'Intelligence Artificielle, je n'arrivais pas à croire ce que je lisais. J'ai rapidement compris que ce qui se passait dans le monde de l'IA n'était pas seulement une question importante, mais de loin LA question la plus importante pour notre avenir. Je voulais donc en apprendre le plus possible à ce sujet, et ceci fait, je voulais m'assurer d'écrire un article qui explique vraiment tout ce que cela recouvre et pourquoi c'est si crucial. Comme on pouvait s'y attendre, ça a pris des proportions énormes, alors j'ai divisé mon post en deux parties. Ceci est la Partie 1 — La Partie 2 est [ici](/waitbutwhy2)._

---

_"Nous sommes à l'aube d'un changement comparable à l'émergence de la vie humaine sur Terre."— Vernor Vinge_

Qu'est-ce que ça fait de se trouver là ?

![La pente est raide](/wbw/part1_01_progress1.png)

On pourrait se dire que c'est un moment d'une grande intensité — mais il faut alors se rappeler ce que ça fait de se trouver sur un axe de temps: on ne peut pas voir ce qui se trouve à sa droite. Donc être là on le ressent plutôt comme ça : :

![La pente est raide](/wbw/part1_02_progress2.jpg)

Ce qui a l'air plutôt normal…

# L'avenir lointain — Bientôt chez vous

Imaginez que vous preniez une machine à voyager dans le temps et que vous retourniez en 1750 — une époque où le monde était plongé dans une panne de courant généralisée, où pour communiquer sur de longues distances il fallait soit hurler à pleins poumons, soit tirer un coup de canon en l'air, et où tous les moyens de transports tournaientau foin. Une fois arrivé à destination, vous chopez un type, vous l'amenez en 2015, puis vous lui faites faire un petit tour et vous observez sa réaction face à tout ce qui l'entoure. On ne peut pas comprendre ce que ça lui ferait de voir des capsules brillantes filant sur une autoroute, de parler à des personnes qui étaient de l'autre côté de l'océan le matin même, de regarder des compétitions sportives qui se déroulent à 1500 km de là, d'écouter un concert qui a eu lieu il y a 50 ans, et de jouer avec mon rectangle magique ensorcelé lui permettant de capturer une image réelle ou d'enregistrer un moment de vie, de faire apparaître une carte avec un point bleu surnaturel qui bouge et lui montre où il est, de voir le visage de quelqu'un et de discuter avec lui alors qu'il est de l'autre côté du pays, et tout un tas d'autres sorcelleriesqui dépassent l'entendement. Et tout ça avant même de lui faire découvrir Internet ou de lui expliquer des choses comme la Station Spatiale Internationale, le Grand Accélérateur de Hadrons, les armes nucléaires ou la relativité générale.

Cette expérience pour lui ne serait ni surprenante, ni choquante, ni même renversante — ces mots ne sont pas assez forts. Il pourrait littéralement en mourir.

Mais voici ce qui est intéressant : Imaginant que ce type retourne lui-même en 1750, et piqué au vif par le fait que nous avons pu observer sa réaction, il décide de tenter l'expérience aussi. Il monterait dans la machine à voyager dans le temps et, reculant de la même distance, il capturerait quelqu'un vivant en l'an 1500, l'amènerait en 1750 et lui montrerait tout. Le gars de 1500 serait choqué par beaucoup de choses — mais il ne mourrait pas. Ce serait beaucoup moins dingue à vivre pour lui, car bien que 1500 et 1750 soient des époques très différentes, elles étaient bien moins différentes que 1750 et 2015.

Le gars de 1500 apprendrait des dingueries sur l'espace et la physique, il serait impressionné par la persistance de l'Europe à s'engager dans la voie de l'impérialisme qui n'était qu'une lubie à son époque, et il devrait revoir sérieusement sa version de la carte du monde. Mais l'observation de la vie quotidienne en 1750 — les transports, les communications, etc. — ne le tuerait certainement pas.

Non, pour que le gars de 1750 s'amuse autant que nous nous sommes amusés avec lui, il devrait remonter bien plus loin — peut-être jusqu'à environ 12 000 av. J.-C., avant la Première Révolution Agricole qui a donné naissance aux premières villes et au concept de civilisation. Si un individu issu d'un monde exclusivement composé de chasseurs-cueilleurs — c'est-à-dire d'une époque où les humains étaient, grosso modo, une espèce animale parmi tant d'autres— voyait les vastes empires humains de 1750 avec leurs églises imposantes, leurs navires traversant les océans, leur concept d'"intériorité domestique", et leur gigantesque montagne de connaissances et de découvertes humaines collectives accumulées — il en mourrait sans doute.

Imaginons maintenant qu'après être tombé raide, cet autre gars lui-même était piqué au vif et voulait faire la même chose. S'il remontait 12 000 ans en arrière jusqu'à 24 000 av. J.-C. et amenait un gars à la date de 12 000 av. J.-C., qu'il lui fasse tout visiter, le gars dirait : "Bon, OK, c'était quoi le but ? Aucun intérêt."Pour que le gars de 12 000 av. J.-C. s'amuse autant, il devrait remonter à plus de 100 000 ans et trouver quelqu'un à qui il pourrait montrer le feu et le langage pour la première fois.

Pour qu'une personne propulsée dans le futur meure du choc qu'elle subirait, elle doit avancer de suffisamment d'années pour qu'elle atteigne une "progression mortelle", ou une Unité de Progression Mortelle (UPM). Ainsi, une UPM a pris plus de 100 000 ans à l'époque des chasseurs-cueilleurs, mais au rythme post-Révolution Agricole, il n'a fallu que 12 000 ans environ. Le monde post-Révolution Industrielle a progressé si rapidement qu'une personne de 1750 n'a besoin d'avancer que de quelques centaines d'années pour qu'une UPM se produise.

Ce modèle — le progrès humain qui s'accélère au fil du temps — est ce que le futurologue Ray Kurzweil appelle la Loi des Rendements Accélérés de l'histoire humaine. Cela se produit parce que les sociétés plus avancées ont la capacité de progresser à un rythme plus rapide que les sociétés moins avancées — précisément _parce qu'elles sont plus avancées_. L'humanité du XIXe siècle en savait plus et bénéficiait d'une meilleure technologie que l'humanité du XVe siècle, il n'est donc pas surprenant que l'humanité ait fait beaucoup plus de progrès au XIXe siècle qu'au XVe siècle — l'humanité du XVe siècle ne pouvait pas rivaliser avec l'humanité du XIXe siècle. ((1)) {(1)}<sup>← cliquez sur les 2</sup>

Ça marche aussi à plus petite échelle. Le film _Retour vers le Futur_ est sorti en 1985, et "le passé"se déroulait en 1955. Dans le film, quand Michael J. Fox remonte à 1955, il y a tout un tas de choses auxquelles il ne s'attend pas : que les téléviseurs soient une nouveauté, le prix des sodas, que les gens n'apprécient pas les solos de guitare électrique qui vous vrillent les oreilles et que le langage courant soit si différent. C'était un autre monde, certes — mais si le film était tourné aujourd'hui et que le passé se situait en 1985, le film pourrait jouer _beaucoup plus_ sur des différences _bien plus_ grandes. Le personnage serait dans une époque d'avant les ordinateurs personnels, avant internet et les téléphones portables — le Marty McFly d'aujourd'hui, un adolescent né à la fin des années 90, serait bien plus déboussolé en 1985 que le Marty McFly du film ne l'était en 1955.

C'est pour la même raison que nous venons d'évoquer — la Loi des Rendements Accélérés. Le taux moyen de progression entre 1985 et 2015 était plus élevé que celui entre 1955 et 1985 — parce que le monde de 2015 était un monde plus avancé — si bien que beaucoup plus de changements se sont produits dans ces 30 dernières années que dans les 30 précédentes.

Donc — les avancées vont croissant et se produisent de plus en plus rapidement. Ce qui laisse présager des changements à venir assez radicaux, non ?

Kurzweil émet l'hypothèse que les progrès de l'ensemble du XXe siècle auraient pu être accomplis en seulement 20 ans au rythme de progression de l'an 2000 — en d'autres termes, dès 2000, le rythme de progression était cinq fois plus rapide que le taux moyen de progression du XXe siècle. Il est convaincu qu'un _autre_ siècle de progrès a eu lieu entre 2000 et 2014, et qu'encore un autre siècle de progrès aura lieu d'ici 2021, en seulement sept ans. Quelques décennies plus tard, il croit qu'un siècle de progrès se produira plusieurs fois dans la même année, et plus tard encore, en moins d'un mois. Tout compte fait, en raison de la Loi des Rendements Accélérés, Kurzweil pense que le XXIe siècle accomplira _1 000 fois_ les progrès du XXe siècle. {(2)}

Si Kurzweil et ceux qui sont d'accord avec lui ont raison, nous pourrions être aussi stupéfaits en 2030 que notre gars de 1750 l'était en 2015 — c'est-à-dire que la prochaine UPM pourrait ne prendre que quelques décennies — et le monde en 2050 pourrait être tellement différent du monde actuel que nous aurions du mal à le reconnaître.

Ce n'est pas de la science-fiction. C'est ce que de nombreux scientifiques plus intelligents et plus compétents que vous ou moi croient dur comme fer — et si l'on regarde l'histoire, en toute logique, on devrait arriver à la même projection.

Alors qu'est-ce qui fait que, quand je dis un truc comme "dans 35 ans, le monde pourrait être totalement méconnaissable", vous pensez : "Cool ... mais naaaaan"? Il y a trois raisons qui font que nous sommes sceptiques face aux prévisions abracadabrantes concernant l'avenir:

**1) En termes d'histoire, nous pensons en ligne droite.** Quand nous imaginons les progrès des 30 prochaines années, nous regardons les progrès des 30 années précédentes comme un indicateur de ce qui est susceptible de se produire. Quand nous réfléchissons à l'ampleur des changements dans le monde au XXIe siècle, nous prenons simplement les progrès du XXe siècle et les ajoutons à l'année 2000. C'est la même erreur que notre homme de 1750 a commise lorsqu'il a fait venir quelqu'un de 1500 et qu'il s'attendait à ce qu'il soit aussi renversé que lui-même l'avait été en avançant de la même distance dans le futur. Intuitivement, nous avons tendance à penser de manière _linéaire_, alors que nous devrions penser de manière _exponentielle_. En étant un peu plus malin, on pourrait prédire les avancées des 30 prochaines années non pas en regardant les 30 dernières, mais en se basant sur le taux de progrès _actuel_. Ce serait plus précis, mais encore loin de la réalité. Pour penser correctement l'avenir, il faut imaginer les choses comme évoluant à un rythme _bien plus rapide_ que celui auquel elles évoluent actuellement.

![La pente est raide](/wbw/part1_03_progress3.png)

**2) La trajectoire de l'histoire récente raconte souvent une histoire déformée.** Premièrement, même une courbe exponentielle abrupte peut sembler linéaire si l'on ne regarde qu'un tout petit segment, de la même manière qu'un petit segment d'un énorme cercle, observé de près, ressemble quasiment à une ligne droite. Deuxièmement, la croissance exponentielle n'est pas totalement fluide et uniforme. Kurzweil explique que le progrès se produit sous forme de "courbes en S":

![La pente est raide](/wbw/part1_04_progress4.png)

Un "S"est créé par la vague de progrès lorsqu'un nouveau paradigme déferle sur le monde. La courbe traverse trois phases :

    1. Une croissance lente (la phase initiale de la croissance exponentielle)
    2. Une croissance rapide (la phase secondaire et explosive de la croissance exponentielle)
    3. Un ralentissement lorsque le paradigme en question arrive à maturité {(3)}

Si vous ne regardez que l'histoire très récente, la partie de la courbe en S où vous vous trouvez peut altérer votre perception de la rapidité des progrès. La période entre 1995 et 2007 a vu l'explosion d'Internet, l'apparition de Microsoft, Google et Facebook dans l'espace public, la naissance des réseaux sociaux et l'introduction des téléphones portables, puis des smartphones. C'était la Phase 2 : la période de croissance rapide du S. Mais de 2008 à 2015, les avancées ont été moins révolutionnaires, du moins sur le plan technologique. Quelqu'un qui réfléchit à l'avenir aujourd'hui pourrait examiner les dernières années pour évaluer le rythme actuel des progrès, mais il passerait à côté de l'essentiel. En réalité, il est fort probable qu'une nouvelle et immense poussée de croissance de Phase 2 soit en gestation.

**3) Quand il s'agit de l'avenir, notre propre expérience fait de nous de vieux grincheux.** Nous forgeons les idées que nous nous faisons du monde à partir de notre expérience personnelle, et cette expérience a ancré dans notre esprit l'idée que le rythme de croissance du passé récent constitue "le cours normal des choses". Nous sommes également limités par notre imagination, qui s'appuie sur notre expérience pour élaborer des prédictions, mais souvent, ce que nous savons ne nous donne pas les outils nécessaires pour réfléchir précisément à l'avenir.((2)) Quand nous entendons une prédiction sur l'avenir qui contredit notre conception basée sur notre expérience du _cours naturel des choses_, nous pensons instinctivement que cette prédiction est naïve. Si je vous dis, un peu plus loin dans ce texte, que vous pourriez bien vivre jusqu'à 150 ou 250 ans, voire _ne jamais mourir_, votre instinct serait de penser : "C'est stupide — s'il y a bien une chose que je sais de l'histoire, c'est que tout le monde meurt."Et c'est vrai, personne dans le passé n'a échappé à la mort. Mais personne ne volait non plus dans des avions avant que les avions ne soient inventés.

Donc même si _"naaaaan !"_ vous semble être la réaction logique à la lecture de ce billet, ce n'est probablement pas le cas. Le fait est que, si nous sommes véritablement logiques et que nous nous attendons à ce que les tendances historiques se poursuivent, nous devrions en conclure que beaucoup, beaucoup, _beaucoup_ plus de changements sont amenés à se produire dans les décennies à venir que ce à quoi, intuitivement, nous nous attendons. La logique suggère également que si l'espèce la plus avancée d'une planète continue de faire des bonds de plus en plus grands à un rythme toujours plus rapide, à un moment donné, elle fera un bond si gigantesque qu'il transformera complètement la vie telle qu'elle la connaît ainsi que sa perception de ce que signifie être un humain—un peu comme l'évolution, qui a continué à faire de grands bonds vers l'intelligence jusqu'à produire finalement un bond si important pour aboutir à l'être humain qu'il a complètement modifié ce que signifiait, pour toute créature, le fait de vivre sur Terre. Et si vous prenez un moment pour lire ce qui se passe aujourd'hui dans les domaines de la science et de la technologie, vous commencez à percevoir de nombreux signes qui laissent discrètement entendre que la vie telle que nous la connaissons actuellement ne pourra pas résister au bond qui se prépare.

________________

# Le chemin vers la superintelligence

# Qu'est-ce que l'IA ?

Si vous êtes comme moi, vous pensiez peut-être que l'intelligence artificielle était un concept loufoque de science-fiction, mais dernièrement, vous avez entendu des personnes sérieuses en parler, et vous ne comprenez pas tout à fait ce que c'est.

Il y a trois raisons qui font que beaucoup de gens ne saisissent pas vraiment le terme d'IA :

**1) Nous associons l'IA aux films.** Star Wars. Terminator. 2001 : L'Odyssée de l'espace. Même les Jetsons. Et tout cela relève de la fiction, tout comme les personnages qui sont des robots. Tout cela rend l'IA un peu fictive à nos yeux.

**2) L'IA est un vaste sujet.** Elle va de la calculatrice de votre téléphone aux voitures autonomes, en passant par une chose qui pourrait changer le monde de manière spectaculaire à l'avenir. L'IA englobe tout cela à la fois, ce qui peut prêter à confusion.
**3) Nous utilisons l'IA tout le temps dans notre vie quotidienne, mais nous ne nous rendons pas vraiment compte que c'est de l'IA.** John McCarthy, qui a inventé le terme "intelligence artificielle"en 1956, se plaignait de ce que "dès que cela fonctionne, on ne l'appelle plus IA."{(4)} À cause de ce phénomène, l'IA a souvent l'air d'être une sorte de prophétie concernant l'avenir plutôt qu'une réalité. En même temps, cela donne l'impression qu'il s'agit d'un concept issu de la culture pop du passé qui ne s'est jamais concrétisé. Ray Kurzweil confie qu'il entend des gens affirmer que l'IA a périclité dans les années 1980, ce qui pour lui revient à "affirmer qu'Internet est mort lors de l'effondrement des bulles dot-com au début des années 2000."{(5)}

Mettons donc les choses au clair. Tout d'abord, arrêtez de penser aux _robots_. Un robot est un _réceptacle_ pour l'IA, ayant parfois forme humaine, parfois non — mais l'IA elle-même est l'ordinateur _à l'intérieur_ du robot. L'IA est le cerveau, et le robot est son corps—si tant est qu'elle en ait un. Par exemple, le logiciel et les données derrière Siri constituent une IA, la voix féminine que nous entendons est une personnification de cette IA, et aucun robot n'entre dans le processus.

Deuxièmement, vous avez probablement entendu parler du terme "singularité"ou "singularité technologique". Ce terme a été utilisé en mathématiques pour décrire une situation comparable à une asymptote où les règles normales ne s'appliquent plus. Il a été utilisé en physique pour décrire un phénomène comme un trou noir infiniment petit et dense, ou le point où tout était comprimé juste avant le Big Bang. Là encore, des situations où les règles habituelles ne s'appliquent plus. En 1993, Vernor Vinge a écrit [un essai célèbre](https://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html) dans lequel il a appliqué ce terme au moment à venir où l'intelligence de notre technologie dépassera la nôtre—un moment pour lui où la vie telle que nous la connaissons sera à jamais transformée et où les règles normales ne s'appliqueront plus. Ray Kurzweil a ensuite brouillé les cartes en définissant la singularité comme l'instant où la Loi des Rendements Accélérés atteindra un rythme si effréné que les progrès technologiques se produiront à une vitesse apparemment infinie, après quoi nous vivrons dans un tout nouveau monde. J'ai constaté que de nombreux penseurs en IA d'aujourd'hui ont cessé d'utiliser ce terme, qui est de toute façon déroutant, donc je ne l'utiliserai pas beaucoup ici (même si nous nous concentrerons sur cette *idée* tout au long du texte).


Enfin, bien qu'il existe de nombreux types ou formes d'IA, car l'IA est un concept très vaste, les catégories critiques auxquelles nous devons réfléchir se basent sur le *calibre* de l'IA. Il existe trois grandes catégories de calibre d'IA :


**Calibre d'IA 1) Intelligence Artificielle Étroite (ANI)** :  Parfois appelée *IA faible*, l'Intelligence Artificielle Étroite est une IA qui se spécialise dans *un* domaine. Il existe une IA capable de battre le champion du monde d'échecs aux échecs, mais c'est la seule chose qu'elle sait faire. Demandez-lui de trouver une meilleure façon de stocker des données sur un disque dur, et elle vous fixera d'un regard vide.



**Calibre d'IA 2) Intelligence Artificielle Générale (AGI)** : Parfois appelée *IA forte* ou *IA de niveau humain*, l'Intelligence Artificielle Générale désigne un ordinateur aussi intelligent qu'un humain *dans tous les domaines* — une machine capable d'exécuter n'importe quelle tâche intellectuelle qu'un être humain peut accomplir. Créer une AGI est une tâche *bien plus* difficile que de créer une IA étroite, et nous n'y sommes pas encore parvenus. La professeure Linda Gottfredson décrit l'intelligence comme "une capacité mentale très générale qui, entre autres choses, implique la capacité de raisonner, de planifier, de résoudre des problèmes, de penser abstraitement, de comprendre des idées complexes, d'apprendre rapidement et d'apprendre à partir de l'expérience."Une AGI serait capable de faire tout cela aussi facilement que vous.

**Calibre d'IA 3) Superintelligence Artificielle (ASI)** : Nick Bostrom, philosophe à l'université d'Oxford et penseur de premier plan en matière d'IA, [définit](https://nickbostrom.com/superintelligence) la superintelligence comme "un intellect beaucoup plus intelligent que les meilleurs cerveaux humains dans pratiquement tous les domaines, y compris la créativité scientifique, la sagesse générale et les compétences sociales."L'ASI va d'un ordinateur légèrement plus intelligent qu'un humain à un ordinateur des trilliards de fois plus intelligent — dans tous les domaines. L'ASI est la raison qui fait que le sujet de l'IA est si passionnant et pourquoi les mots "immortalité"et "extinction"apparaîtront plusieurs fois dans ces textes.



À ce jour, les humains ont conquis le niveau le plus bas de l'IA — l'IA étroite — de nombreuses manières, et elle est omniprésente. La Révolution de l'IA est le périple qui mène de l'IA étroite, en passant par l'AGI, jusqu'à l'ASI — un périple auquel nous pourrions bien ne pas survivre, mais qui, dans tous les cas, changera absolument tout.


Examinons de près ce que pensent les experts du domaine concernant ce périple et pourquoi cette révolution pourrait se produire bien plus tôt que vous ne le pensez :

_______

# Où nous en sommes actuellement — Un monde fonctionnant grâce à l'IA étroite

L'Intelligence Artificielle étroite (ANI) est une intelligence informatique qui égale ou dépasse l'intelligence ou l'efficacité humaine dans un domaine *spécifique*. Voici quelques exemples :




* Les voitures regorgent de systèmes ANI, du calculateur qui détermine quand activer le système antiblocage des freins à celui qui règle les paramètres des systèmes d'injection de carburant. [La voiture autonome](https://www.youtube.com/channel/UCCLyNDhxwpqNe3UeEmGHl8g) de Google, actuellement en phase de test, contient des systèmes d'IA étroite robustes qui lui permettent de percevoir et de réagir au monde qui l'entoure.
* Votre téléphone est une petite usine d'ANI. Lorsque vous naviguez avec une application de géolocalisation, recevez des recommandations musicales personnalisées via Pandora, consultez la météo du lendemain, parlez à Siri ou effectuez des dizaines d'autres activités quotidiennes, vous utilisez l'IA étroite.
* Votre filtre anti-spam de courrier électronique est un exemple classique d'ANI— cela part d'une intelligence artificielle lui permettant de déterminer ce qui est du spam ou non, puis il apprend et adapte son intelligence à vous à mesure qu'il acquiert de l'expérience en se basant sur vos préférences particulières. Le thermostat Nest fait la même chose en intégrant vos habitudes pour s'y adapter.
* Vous connaissez ce truc flippant qui se passe quand vous recherchez un produit sur Amazon et que vous le retrouvez ensuite comme un produit "recommandé pour vous"sur un *autre* site, ou quand Facebook semble deviner comme par magie qui vous devriez ajouter comme ami ? C'est un réseau de systèmes ANI qui travaillent ensemble pour s'informer mutuellement de qui vous êtes et de ce que vous aimez, puis pour utiliser ces informations pour décider de ce qu'ils vont vous montrer. Même chose pour la recommandation d'Amazon "Les personnes ayant acheté ceci ont également acheté..."- c'est un système ANI dont le travail consiste à collecter des informations à partir du comportement de millions de clients et à synthétiser ces informations pour vous inciter subtilement à acheter plus de choses.
* Google Traduction est un autre système ANI classique - remarquablement adapté à une tâche étroite et précise. La reconnaissance vocale en est un autre, et il existe de nombreuses applications qui utilisent ces deux IA étroites en duo, vous permettant de prononcer une phrase dans une langue et de faire générer la même phrase dans une autre par votre téléphone.
* Quand votre avion atterrit, ce n'est pas un humain qui décide à quelle porte il doit se rendre. Tout comme ce n'est pas un humain qui a déterminé le prix de votre billet.
* Les meilleurs joueurs mondiaux de dames, d'échecs, de Scrabble, de Backgammon et d'Othello sont maintenant tous des systèmes ANI.
* Google Recherche est un grand cerveau ANI avec des méthodes incroyablement sophistiquées pour classer les pages et déterminer ce qu'il doit vous montrer en particulier. Il en va de même pour le fil d'actualité de Facebook.
* Et ce ne sont que quelques exemples dans le domaine du grand public. Des systèmes d'IA étroites sophistiqués sont largement utilisés dans des secteurs et des industries comme l'armée, dans la production et la finance (les traders algorithmiques à haute fréquence représentent plus de la moitié des actions négociées sur les marchés américains {(6)}), et dans des systèmes experts comme ceux qui aident les médecins à établir des diagnostics ou bien encore - cela a fait les gros titres – dans [Watson](https://www.ibm.com/watsonx) de chez IBM qui contenait suffisamment d'informations factuelles et comprenait assez bien le langage très allusif du présentateur Alex Trebek pour battre haut la main les champions les plus prolifiques de Jeopardy.

&nbsp;

Les systèmes ANI tels qu'ils existent actuellement ne font pas particulièrement peur. Au pire, une ANI défectueuse ou mal programmée peut provoquer une catastrophe isolée comme une panne de réseau électrique, un incident dangereux dans une centrale nucléaire, ou un désastre sur les marchés financiers (comme le [Flash Crash de 2010](https://ritholtz.com/wp-content/uploads/2010/10/flash-crash-dow-popup.png) où un programme ANI a mal réagi à une situation inattendue et a fait plonger brièvement le marché boursier, faisant s'évaporer 1000 milliards de dollars de valeurs boursières, dont seulement une partie fut récupérée après correction de l'erreur).

Mais bien que l'ANI ne puisse pas constituer une *menace existentielle*, il serait bon que nous considérions cet écosystème de plus en plus large et complexe d'ANI relativement inoffensives comme un précurseur de l'ouragan qui va bouleverser le monde. Chaque nouvelle innovation ANI ajoute silencieusement un pavé de la route qui mène vers l'AGI et l'ASI. Ou pour le décrire [à la façon d'Aaron Saenz](http://singularityhub.com/2010/08/10/we-live-in-a-jungle-of-artificial-intelligence-that-will-spawn-sentience/), les systèmes ANI de notre monde sont "comme les acides aminés dans la boue primordiale de la Terre primitive"- la matière inanimée de la vie qui, un jour, s'est réveillée sans crier gare.

# La Route de l'IA étroite à l'IAG (Intelligence Artificielle Générale)

### <u>Pourquoi C'est Si Difficile</u>



Ce n'est que lorsqu'on s'attaque à la tâche incroyablement difficile d'essayer de créer un ordinateur aussi intelligent que nous que l'on peut commencer à apprécier l'intelligence humaine. Construire des gratte-ciels, envoyer des humains dans l'espace, comprendre les détails du Big Bang - tout cela est bien plus facile que de comprendre notre propre cerveau ou comment créer quelque chose d'aussi extraordinaire. À l'heure actuelle, le cerveau humain reste l'objet le plus complexe de l'univers connu.

Ce qui est intéressant, c'est que les étapes les plus délicates pour construire l'AGI (un ordinateur aussi intelligent que les humains en général, pas seulement dans une spécialité étroite) ne sont pas celles auxquelles on pourrait penser intuitivement. Construire un ordinateur capable de multiplier deux nombres de dix chiffres en une fraction de seconde - incroyablement facile. En construire un capable de regarder un chien et de répondre s'il s'agit d'un chien ou d'un chat - spectaculairement difficile. Créer une IA capable de battre n'importe quel humain aux échecs ? Fait. En créer une capable de lire un paragraphe d'un livre d'images pour enfants de six ans et non seulement de reconnaître les mots, mais de comprendre leur *signification* ? Google dépense actuellement des [milliards](https://www.wired.com/2014/01/google-buying-way-making-brain-irrelevant/) de dollars pour y parvenir. Les choses difficiles - comme le calcul, les stratégies des marchés financiers et la traduction des langues - sont d'une facilité déconcertante pour un ordinateur, tandis que les choses faciles - comme la vision, le mouvement et la perception - sont atrocement difficiles pour lui. Ou, comme le dit le scientifique en informatique Donald Knuth, "L'IA a jusqu'à présent réussi à faire essentiellement tout ce qui nécessite de la 'réflexion', mais ne parvient pas à faire la plupart de ce que les humains et les animaux font 'sans réfléchir'."{(7)}


Ce que l'on comprend rapidement en y réfléchissant, c'est que ces choses qui nous semblent faciles sont en réalité incroyablement compliquées, et ne nous paraissent faciles que parce que ces compétences ont été optimisées chez nous (et chez la plupart des animaux) par des centaines de millions d'années d'évolution animale. Quand vous tendez votre main vers un objet, les muscles, les tendons et les os de votre épaule, de votre coude et de votre poignet effectuent instantanément une longue série d'opérations physiques, en coordination avec vos yeux, pour vous permettre de déplacer votre main en ligne droite à travers trois dimensions. Cela ne semble vous demander aucun effort parce que vous avez un logiciel cérébral perfectionné dans ce but. C'est le même principe qui s'applique quand on se demande comment un logiciel malveillant peut être assez bête pour ne pas arriver à résoudre un test consistant à reconnaître des mots affichés en écriture torduequand on veut ouvrir un nouveau compte sur un site : ce qui est impressionnant, c'est que votre cerveau soit *capable* de le faire.

D'un autre côté, multiplier de grands nombres ou jouer aux échecs sont des activités récentes pour les créatures biologiques que nous sommes et nous n'avons pas eu le temps d'évoluer assez pour être performants dans ces domaines, donc un ordinateur n'a pas besoin de trop se fatiguer pour nous battre. Réfléchissez-y : préféreriez-vous construire un programme capable de multiplier de grands nombres ou un programme capable de capter l'essence de la lettre B au point de pouvoir la reconnaître instantanément, quelle que soit la police ou l'écriture manuscrite parmi des milliers de variations possibles ?

Un petit exemple pour se détendre : quand vous regardez cette image, vous et un ordinateur pouvez tous les deux comprendre qu'il s'agit d'un rectangle composé d'une alternance de deux nuances de couleurs distinctes:

![recognition](/wbw/part1_05_recognition1.png)

Jusqu'ici vous êtes à égalité. Mais si vous enlevez le fond noir et que vous révélez l'image complète…

![recognition](/wbw/part1_06_recognition2.png)

...vous n'avez aucun problème pour décrire les divers cylindres opaques et translucides, les lamelles et les coins en 3D, tandis que l'ordinateur échouerait lamentablement. Il décrirait ce qu'il voit - une variété de formes en deux dimensions de plusieurs nuances différentes – et techniquement, c'est ce qui est représenté. Votre cerveau fait un tas de trucs complexes pour interpréter la profondeur sous-jacente, le mélange des nuances et l'éclairage de la pièce que l'image cherche à représenter.{(8)} Et en regardant l'image ci-dessous, un ordinateur voit un collage bidimensionnel blanc, noir et gris, tandis que vous voyez facilement ce que c'est vraiment - une photo d'un caillou entièrement noir en 3D : 

![Caillou](/wbw/part1_07_rock.jpg)

Et tout ce que nous venons d'évoquer ne concerne encore que la perception et le traitement d'informations statiques. Pour atteindre le niveau de l'intelligence humaine, un ordinateur devrait saisir des choses comme la différence entre des expressions faciales subtiles, savoir faire la distinction entre ce que signifie être content, soulagé, satisfait, ravi et heureux, et pourquoi *Braveheart* était un film génial mais *The Patriot* était nul.

Coton.



Alors comment y arriver ?

### <u> Première Clé pour Créer l'AIG : Augmenter la Puissance de calcul </u>

Une chose nécessaire pour l'AGI est une augmentation de la puissance du matériel informatique. Si un système d'IA doit être aussi intelligent que le cerveau, il devra égaler la capacité de calcul brute du cerveau.

Une façon d'exprimer cette capacité est de calculer le nombre total de calculs par seconde (cps) que le cerveau pourrait gérer, en additionnant le nombre total maximal de cps réalisables par chacune des structures cérébrales.

Ray Kurzweil a trouvé un raccourci en prenant une estimation professionnelle des cps d'une structure et son poids par rapport à l'ensemble du cerveau, puis en effectuant un calcul proportionnel pour obtenir une estimation totale. Cela semble un peu hasardeux, mais il l'a fait plusieurs fois avec différentes estimations professionnelles de diverses régions, et le total aboutissait toujours au même ordre de grandeur - environ 10¹⁶, soit 10 quadrillions de cps.

Actuellement, le superordinateur le plus rapide du monde, le [Tianhe-2](https://www.reuters.com/article/2014/11/17/us-china-supercomputer-idUSKCN0J11VV20141117/) chinois, a dépassé ce chiffre, atteignant environ 34 quadrillions de cps. Mais le Tianhe-2 est aussi bien relou, occupant une surface de 720 mètres carrés, consommant 24 mégawatts d'électricité (alors que le cerveau fonctionne avec seulement 20 watts), et coûtant 390 millions de dollars à construire. Ce n'est pas encore le genre d'ordinateur particulièrement adapté à une utilisation généralisée, ni même à la plupart des usages commerciaux ou industriels.



Kurzweil nous suggère de considérer le développement des ordinateurs à la lumière du nombre de cps qu'on peut obtenir pour 1 000 dollars. Lorsque ce chiffre atteindra le niveau humain - 10 quadrillions de cps - cela signifiera que l'AGI pourrait bien devenir une réalité très concrète

[La loi de Moore](https://en.wikipedia.org/wiki/Moore%27s_law) est une règle historiquement fiable selon laquelle la puissance informatique maximale mondiale double approximativement tous les deux ans, ce qui signifie que le progrès du matériel informatique, comme le progrès humain général à travers l'histoire, croît de manière exponentielle. En comparant cela à l'indice de Kurzweil exprimé en cps/1 000 $, nous sommes actuellement à environ 10 billions de cps/1 000 $, pile dans la trajectoire prédite par ce graphique.


![Croissance](/wbw/part1_08_computing_growth.jpg)


Donc, les ordinateurs à 1 000 $ que l'on trouve aujourd'hui dépassent maintenant le cerveau de souris et sont à environ un millième du niveau humain. Cela ne semble pas beaucoup jusqu'à ce que vous vous rappeliez qu'en 1985, nous étions à un billionième du niveau humain, à un milliardième en 1995, et à un millionième en 2005. Être à un millième en 2015 nous place pile dans les temps pour obtenir un ordinateur abordable d'ici 2025 qui rivalise avec la puissance du cerveau humain.

Donc, côté matériel, la puissance brute nécessaire pour l'AGI est techniquement disponible aujourd'hui-même, en Chine, et nous serons prêts pour un matériel capable d'AGI abordable et généralisé dans 10 ans. Mais la puissance de calcul brute seule ne fait pas d'un ordinateur une intelligence générale - la prochaine question est : comment insérer une intelligence de niveau humain dans toute cette puissance ?



### <u>Deuxième clé pour créer l'AGI : La rendre intelligente</u>

C'est la partie désagréable. La vérité est que personne ne sait vraiment comment la rendre intelligente - on débat encore de la façon de créer un ordinateur doté d'une intelligence humaine et capable de savoir ce qu'est un chien, un B mal écrit et un film médiocre. Mais il existe un tas de stratégies farfelues et à un moment donné, il y en a bien une qui va marcher. Voici les trois stratégies les plus courantes que j'ai rencontrées:

**1) Plagier le cerveau.**

C'est un peu comme si on avait des scientifiques qui se creusent les méninges pour comprendre comment ce gamin assis à côté d'eux en classe est si intelligent et a de si bonnes notes aux tests, et que même quand ils travaillent comme des fous, ils ne lui arrivent jamais à la cheville, et puis qui se disent en fin de compte finalement "Bon, et puis merde, je vais juste lui pomper dessus, à ce môme."Ça paraît logique – on est bloqué pour construire un ordinateur super-complexe, et il se trouve qu'il en existe un prototype parfait dans la tête de chacun d'entre nous.

Le monde scientifique travaille dur pour décoder le cerveau et comprendre comment l'évolution a créé un truc aussi génial - [les estimations optimistes](https://www.wired.com/2010/08/reverse-engineering-brain-kurzweil/) disent que nous pouvons y arriver d'ici 2030. Une fois que nous l'aurons fait, nous connaîtrons tous les secrets expliquant pourquoi le cerveau fonctionne de manière si puissante et efficace, et nous pourrons nous en inspirer et voler ses innovations. Un exemple d'architecture informatique qui imite le cerveau est le réseau neuronal artificiel. C'est à la base un réseau de "neurones"transistors, connectés les uns aux autres avec des entrées et des sorties, et il ne sait rien - comme le cerveau d'un nouveau-né. Il "apprend" en essayant d'accomplir une tâche – mettons la reconnaissance de l'écriture manuscrite - et au début, ses décharges neuronales et ses tentatives ultérieures de déchiffrer chaque lettre seront complètement aléatoires. Mais quand on lui dit qu'il a réussi quelque chose, les connexions des transistors dans les voies de décharge qui ont créé cette réponse sont renforcées ; quand on lui dit qu'il s'est trompé, les connexions de ces voies sont affaiblies. Après beaucoup de ces essais et retours, le réseau a, par lui-même, formé des voies neuronales intelligentes et la machine a été optimisée pour la tâche. Le cerveau apprend un peu de la même manière, mais de façon plus sophistiquée, et au fur et à mesure que nous continuons à étudier le cerveau, nous découvrons des moyens ingénieux d'utiliser les circuits neuronaux.

Une forme de plagiat plus extrême repose sur une stratégie appelée "émulation du cerveau entier", où l'objectif est de découper un vrai cerveau en couches fines, de scanner chacune d'elles, d'utiliser un logiciel pour assembler un modèle 3D reconstruit fidèle, puis de mettre en œuvre ce modèle sur un ordinateur puissant. Nous aurions alors un ordinateur officiellement capable de tout ce dont le cerveau est capable - il aurait juste besoin d'apprendre et de rassembler des informations. Si les ingénieurs deviennent de vrais cracks, ils pourraient être capables d'émuler un vrai cerveau avec une précision telle que la personnalité et la mémoire complètes du cerveau seraient conservées intactes une fois l'architecture cérébrale transférée sur un ordinateur. Si le cerveau appartenait à Jim juste avant qu'il ne meure, l'ordinateur qui s'éveillerait alors endosserait l'identité de Jim ([?](https://waitbutwhy.com/2014/12/what-makes-you-you.html)), qui serait une AGI robuste de niveau humain, et nous pourrions maintenant nous atteler à la tâche de faire de Jim une ASI d'une intelligence inimaginable, ce dont il serait probablement absolument ravi.

À quelle distance sommes-nous de l'émulation du cerveau entier ? Eh bien, jusqu'à présent, nous avons [récemment réussi](http://www.smithsonianmag.com/smart-news/weve-put-worms-mind-lego-robot-body-180953399/?no-ist) à émuler un cerveau de ver plat long de 1 mm, qui ne compte que 302 neurones au total. Le cerveau humain en contient 100 milliards. Si cela peut sembler un projet sans espoir, rappelez-vous du pouvoir du progrès exponentiel - maintenant que nous sommes venus à bout du minuscule cerveau du ver, un cerveau de fourmi pourrait suivre dans pas longtemps, puis celui d'une souris, et d'un coup, cela semblera beaucoup plus plausible.

**2) Essayer de faire faire à l'évolution ce qu'elle a déjà fait, mais cette fois pour nous.**

Donc si nous décidons que le test du gamin intelligent est trop difficile à copier, nous pouvons essayer à la place de copier la façon dont il *étudie* lors des tests.

Il y a une chose dont nous sommes certains : Construire un ordinateur aussi puissant que le cerveau est bel et bien possible - l'évolution de notre propre cerveau en est la preuve. Et si le cerveau est trop complexe pour que nous puissions l'émuler, nous pourrions essayer d'émuler son *évolution* à la place. Le fait est que même si nous pouvions émuler un cerveau, ce serait comme essayer de construire un avion en copiant exactement les mouvements d'ailes d'un oiseau - souvent, il vaut bien mieux concevoir des machines en utilisant une approche nouvelle, adaptée à la machine, plutôt qu'en imitant exactement le processus biologique.

Alors, comment pouvons-nous simuler l'évolution pour construire une AGI ? La méthode dite des "algorithmes génétiques", fonctionnerait à peu près comme suit: en répétant sans cesse un processus de performance et d'évaluation (au même titre que les créatures biologiques "performent"en vivant et sont "évaluées"par leur capacité à se reproduire ou non). Un groupe d'ordinateurs essaierait d'effectuer des tâches, et les plus performants seraient autorisés à se *reproduire* entre eux en fusionnant la moitié de leur programmation pour créer un nouvel ordinateur. Les moins performants seraient éliminés. Au bout de très, très nombreuses itérations, ce processus de sélection naturelle produirait des ordinateurs de plus en plus performants. Le défi serait de créer un cycle d'évaluation et de reproduction automatisé pour que ce processus d'évolution puisse se dérouler tout seul.

L'inconvénient du fait de copier l'évolution, c'est que l'évolution aime passer un milliard d'années pour faire les choses et que nous, nous voulons le faire en quelques décennies.

Mais nous disposons de beaucoup d'avantages sur l'évolution. Premièrement, l'évolution n'a pas de vision prospective et fonctionne de manière aléatoire - elle produit plus de mutations inutiles que bénéfiques, mais nous contrôlerions le processus pour qu'il ne soit guidé que par des anomalies utiles et des ajustements ciblés. Deuxièmement, l'évolution ne *vise* rien, pas même l'intelligence - parfois, un environnement pourrait même effectuer une sélection allant *à l'encontre* de l'intelligence supérieure (car elle consomme beaucoup d'énergie). Nous, en revanche, pourrions diriger spécifiquement ce processus évolutif vers l'augmentation de l'intelligence. Troisièmement, pour sélectionner l'intelligence, l'évolution doit innover de multiples façons pour faciliter l'intelligence - comme repenser la production d'énergie des cellules - alors que nous pouvons supprimer ces fardeaux supplémentaires et utiliser des choses comme l'électricité. Il ne fait aucun doute que nous serions beaucoup, beaucoup plus rapides que l'évolution - mais on ne sait toujours pas vraiment si nous serons capables d'améliorer *suffisamment* le processus d'évolution pour en faire une stratégie viable.

**3) Refiler le bébé à l'ordinateur, pas à nous.**

Là on en est au moment où les scientifiques sont carrément désespérés et essaient de programmer le test pour qu'il se passe lui-même. Ce qui pourrait s'avérer la méthode la plus prometteuse de toutes.

L'idée est de construire un ordinateur dont les deux principales compétences seraient de faire de la recherche sur l'IA et d'intégrer à son code les modifications qu'il aurait lui-même effectuées - lui permettant non seulement d'apprendre mais d'améliorer sa propre *architecture*. Nous enseignerions aux ordinateurs à être des informaticiens afin qu'ils puissent amorcer leur propre développement. Et ce serait leur principale mission - comprendre comment se rendre *eux-mêmes* plus intelligents. Je développerai cela plus tard.

#### Tout cela pourrait se produire bientôt

Des avancées matérielles rapides et des expérimentations innovantes en matière de logiciel se produisent simultanément, et l'AGI pourrait nous tomber dessus rapidement et à l'improviste pour deux raisons majeures :

1) La croissance exponentielle est intense et ce qui donne a priori l'impression de se traîner peut accélérer rapidement - ce GIF illustre bien ce concept :

![Exp growth GIF](https://waitbutwhy.com/wp-content/uploads/2015/01/gif)

[Source](https://www.motherjones.com/media/2013/05/robots-artificial-intelligence-jobs-automation/)

2) En matière de logiciels, le progrès peut sembler lent, mais une seule révélation peut instantanément changer le rythme des progrès (pensez par exemple aux difficultés de la science à calculer le fonctionnement de l'univers lorsque les humains pensaient que l'univers était géocentrique, et à quel point la découverte de l'héliocentrisme a soudain vraiment tout simplifié). Idem, dans le cas d'un ordinateur capable de s'améliorer lui-même, nous pourrions avoir l'impression d'être loin du but mais en réalité nous trouver à deux doigts du petit ajustement du système permettant de le rendre 1 000 fois plus efficace et de le propulser vers l'intelligence de niveau humain.


# La Route de l'AGI à l'ASI

À un moment donné, nous atteindrons l'AGI - des ordinateurs dotés d'une intelligence générale de niveau humain. Juste des gens et des ordinateurs vivant ensemble, à égalité.

Ben pas du tout, en fait.

Le problème est qu'une AGI ayant un niveau d'intelligence et une capacité de calcul identiques à un humain aurait quand même des avantages significatifs sur les humains. Comme par exemple :

#### Matériel 

- **Vitesse.** Les neurones du cerveau atteignent un maximum d'environ 200 Hz, tandis que les microprocesseurs actuels (qui sont bien plus lents que ceux que nous aurons quand nous atteindrons l'AIG) fonctionnent à 2 GHz, soit 10 millions de fois plus vite que nos neurones. Et les communications cérébrales internes, qui circulent à environ 120 m/s, sont dépassées de façon effrayante par la capacité d'un ordinateur à communiquer optiquement à la vitesse de la lumière.
- **Taille et stockage.** Le cerveau est contraint à une taille donnée par la forme de notre crâne, et de toute façon il ne pourrait pas beaucoup gagner en taille, sinon les communications internes à 120 m/s prendraient trop de temps pour aller d'une structure cérébrale à une autre. Les ordinateurs peuvent s'étendre à n'importe quelle taille physique, permettant d'utiliser beaucoup plus de matériel, une mémoire vive (RAM) bien plus grande, et une mémoire à long terme (stockage sur disque dur) qui offre à la fois une capacité et une précision bien supérieures aux nôtres.
- **Fiabilité et durabilité.** Ce ne sont pas seulement les types de mémoire d'un ordinateur qui seraient plus précis. Les transistors des ordinateurs sont plus précis que les neurones biologiques, et ils sont moins susceptibles de se détériorer (et peuvent être réparés ou remplacés le cas échéant). Les cerveaux humains se fatiguent facilement, tandis que les ordinateurs peuvent fonctionner sans interruption, à des performances maximales, 24h/24 et 7j/7.

#### Logiciel

- **Capacité d'édition, de mise à jour et éventail de possibilités plus larges.** Contrairement au cerveau humain, les logiciels informatiques peuvent faire l'objet de mises à jour et de corrections ainsi que d'expérimentations, le tout très simplement. Les améliorations pourraient aussi s'étendre à des domaines où les cerveaux humains présentent des faiblesses. Le logiciel de vision humain est superbement sophistiqué, tandis que sa capacité d'ingénierie complexe est assez rudimentaire. Les ordinateurs pourraient égaler les humains en ce qui concerne le logiciel de vision mais pourraient aussi devenir tout aussi affûtés en ingénierie et dans n'importe quel autre domaine.
- **Capacité collective.** Les humains écrasent littéralement toutes les autres espèces en matière de construction d'une vaste intelligence collective. Depuis le développement du langage et la formation de grandes communautés denses, en passant par l'invention de l'écriture et de l'imprimerie, et maintenant intensifiée par des outils comme Internet, l'intelligence collective de l'humanité est l'une des principales raisons pour lesquelles nous avons pu prendre autant d'avance sur toutes les autres espèces. Et les ordinateurs seront bien meilleurs que nous à cet égard. Un réseau mondial d'IA exécutant un programme particulier pourrait se synchroniser régulièrement de sorte que tout ce qu'un ordinateur apprenne serait instantanément téléchargé sur tous les autres ordinateurs. Le groupe pourrait également poursuivre un objectif commun en tant qu'entité unique, car il n'y aurait pas nécessairement d'opinions divergentes, de motivations et d'intérêts personnels, comme nous en avons au sein de la population humaine.{(10)}

L'IA, qui atteindra probablement l'AGI en étant programmée pour s'améliorer elle-même, ne considèrerait pas "l'intelligence de niveau humain"comme un jalon important – ce n'est un marqueur pertinent que de notre point de vue - et n'aurait aucune raison de "s'arrêter"à notre niveau. Et étant donné les avantages que possède déjà une AGI équivalente à l'intelligence humaine, il est assez évident qu'elle n'atteindrait l'intelligence humaine que durant un bref instant avant de poursuivre sa course en direction de l'intelligence supra-humaine.

Quand ça arrivera, il est fort probable qu'on aura le choc de notre vie. C'est que, de *notre* point de vue : A) Bien qu'il existe des paliers en matière d'intelligence animale, nous nous accordons sur sa caractéristique principale qui est d'être nettement inférieure à la nôtre, et B) Nous considérons les humains les plus intelligents comme étant BEAUCOUP plus intelligents que les humains les moins intelligents. Un peu comme ceci :

![distorted_intelligence](/wbw/part1_09_intelligence1.jpg)


Ainsi, à mesure que l'intelligence de l'IA croît de façon exponentielle, se rapprochant chaque jour un peu plus de la nôtre, nous avons le sentiment qu'elle devient plus intelligente... *pour un animal*. Puis, lorsqu'elle atteindra le niveau de capacité le plus bas de l'humanité — Nick Bostrom utilise le terme "idiot du village"— nous dirons : "Waou, on dirait un humain mais pas très futé. Trop mimi !"Le truc c'est que, sur le spectre global de l'intelligence, *tous* les humains, de l'idiot du village à Einstein, se situent dans une plage très étroite. Donc, *juste* après avoir atteint le niveau de l'idiot du village et avoir été déclarée comme étant une intelligence artificielle générale (AGI), elle deviendra soudain plus intelligente qu'Einstein, et on ne va pas comprendre ce qui nous arrive:


![distorted_intelligence](/wbw/part1_10_intelligence2.png)



Et ensuite… Il se passe quoi ?

### <u>Une explosion d'intelligence</u>

J'espère que vous avez apprécié le sentiment de "normalité"jusqu'ici, parce que c'est maintenant que ce sujet devient totalement barré et carrément effrayant, et ce sera comme ça jusqu'au bout. Je tiens à vous rappeler que tout ce que je vais dire est réel — de la science réelle et des prévisions bien documentées sur l'avenir, issues d'un grand éventail des penseurs et scientifiques les plus respectés. Gardez ça bien présent à l'esprit.

Bref, comme je l'ai dit plus haut, la plupart de nos modèles actuels pour atteindre l'AGI sont basés sur l'idée que l'IA y parviendra par auto-amélioration. Et une fois qu'elle atteindra l'AGI, même des systèmes initialement formés et développés par des méthodes qui ne reposaient pas sur l'auto-amélioration seront dès lors suffisamment intelligents pour commencer à s'auto-améliorer s'ils le veulent.((3))

Et voici où nous abordons un concept vraiment dingue: **l'auto-amélioration récursive**. Ça donne à peu près ça :
Un système d'IA à un certain niveau — disons, le niveau d'un idiot du village humain — est programmé avec l'objectif d'améliorer sa propre intelligence. Une fois qu'il le fait, il devient *plus intelligent* — peut-être qu'à ce stade, il est au niveau d'Einstein — donc, lorsqu'il travaille à améliorer son intelligence, avec une intelligence au niveau d'Einstein, cela devient plus facile et il peut faire des progrès plus importants. Ces progrès le rendent *beaucoup plus* intelligent que n'importe quel humain, lui permettant de faire des avancées *encore plus importantes*. À mesure que ces avancées deviennent plus massives et plus rapides, l'AGI croît rapidement en intelligence et atteint bientôt le niveau superintelligent d'un système ASI. C'est ce qu'on appelle une explosion d'intelligence {(11)}, et c'est l'exemple ultime de la loi des rendements accélérés.

Il y a polémique sur la rapidité avec laquelle l'IA atteindra une intelligence générale comparable à celle des humains. Selon un sondage auprès de centaines de scientifiques, l'année médiane faisant consensus sur la probabilité d'atteindre l'AGI est 2040. Cela ne semble pas si proche, jusqu'à ce que l'on considère que de nombreux experts dans ce domaine pensent qu'il est probable que la progression de l'AGI à l'ASI se produise très rapidement. Par exemple, le scénario suivant pourrait se produire :

*Il faut des décennies pour qu'un premier système d'IA atteigne un faible niveau d'intelligence générale, mais cela finit par arriver. Un ordinateur est capable de comprendre le monde qui l'entoure aussi bien qu'un enfant humain de quatre ans. Puis, soudain, une heure après avoir franchi ce cap, le système accouche de la grande théorie de la physique qui unifie la relativité générale et la mécanique quantique, quelque chose qu'aucun humain n'a pu accomplir de manière définitive. 90 minutes plus tard, l'IA est devenue une ASI, 170 000 fois plus intelligente qu'un humain.*

Une superintelligence d'une telle ampleur est quelque chose que nous ne pouvons absolument pas comprendre, pas plus qu'un bourdon ne peut comprendre l'économie keynésienne. Dans notre monde, être intelligent signifie avoir un QI de 130, et être stupide signifie un QI de 85—nous n'avons pas de mot pour un QI de 12 952.

Ce que nous savons, en revanche, c'est que la domination totale des humains sur Terre illustre une règle claire : *avec l'intelligence vient le pouvoir*. Ce qui signifie qu'une ASI, une fois créée, sera l'être le plus puissant de l'histoire de la vie sur Terre, et que tous les êtres vivants, y compris les humains, seront entièrement à sa merci — *et cela pourrait arriver dans les prochaines décennies*.

Si nos cerveaux modestes ont été capables d'inventer le Wi-Fi, alors une entité 100, 1 000, voire 1 milliard de fois plus intelligente que nous ne devrait avoir aucun problème à contrôler la position de chaque atome dans le monde à sa guise, à tout moment. Tout ce que nous considérons comme de la magie, tous les pouvoirs que nous prêtons à un Dieu suprême, seront des activités aussi banales pour l'ASI que le fait d'actionner un interrupteur pour nous.

Créer des technologies pour inverser le vieillissement humain, guérir les maladies, éradiquer la faim et même vaincre la mortalité, reprogrammer le climat pour protéger l'avenir de la vie sur Terre—tout cela deviendra soudain possible. Mais tout aussi possible est la fin immédiate de toute vie sur Terre. En ce qui nous concerne, si une ASI voit le jour, il y aura désormais un Dieu omnipotent sur Terre—et la question cruciale pour nous est :

# **Est-ce que ce sera un Dieu bienveillant ?**

C'est le sujet de [la partie 2](/waitbutwhy2) de ce post.

(1): OK donc il y a 2 types de notes différents. Les cercles bleus sont ceux qui sont marrants / intéressants et que je vous conseille de lire. Ce sont des informations supplémentaires ou des pensées que je n'ai pas voulu mettre dans le texte principal, soit parce que ce sont des réflexions marginales, soit parce que je veux dire quelque chose d'un peu trop bizarre pour être simplement intégré dans le texte normal.

(2): Kurzweil fait remarquer que son téléphone est, comparé à son ordinateur du MIT d'il y a 40 ans, un million de fois plus petit, un million de fois moins cher, et 1000 fois plus puissant. Bonne chance pour estimer où un 2e bond similaire nous amènerait, sans même parler d'un bond encore plus extrême - puisque que le progrès avance exponentiellement.

(3): Beaucoup plus sur ce que ça signifie pour un ordinateur de “vouloir” quelque chose dans la partie 2

{1}: Les carrés gris sont des objets ennuyeux et si vous cliquer sur un carré gris ça va vous barber. C’est uniquement pour les sources et les citations.

{2}: Kurzweil, [The Singularity is Near](https://www.amazon.com/gp/product/0143037889/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0143037889&linkCode=as2&tag=wabuwh00-20&linkId=54Q62R5PYJBEENTP), 39.

{3}: Kurzweil, [The Singularity is Near](https://www.amazon.com/gp/product/0143037889/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0143037889&linkCode=as2&tag=wabuwh00-20&linkId=54Q62R5PYJBEENTP), 84.

{4}: Vardi, [Artificial Intelligence: Past and Future](http://cacm.acm.org/magazines/2012/1/144824-artificial-intelligence-past-and-future/fulltext), 5.

{5}: Kurzweil, The Singularity is Near](https://www.amazon.com/gp/product/0143037889/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0143037889&linkCode=as2&tag=wabuwh00-20&linkId=54Q62R5PYJBEENTP), 392

{6}: Bostrom, [Superintelligence: Paths, Dangers, Strategies](https://www.amazon.com/gp/product/0199678111/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0199678111&linkCode=as2&tag=wabuwh00-20&linkId=LBOTX2G2R72P5EUA), loc. 597

{7}:  Nilsson, [The Quest for Artificial Intelligence: A History of Ideas and Achievements](https://www.amazon.com/gp/product/0521122937/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0521122937&linkCode=as2&tag=wabuwh00-20&linkId=QIJQME4U3J2KZRRY), 318.

{8}:  Pinker, [How the Mind Works](https://www.amazon.com/gp/product/1491514965/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=1491514965&linkCode=as2&tag=wabuwh00-20&linkId=NJ47RPDRBVZA6QPU), 36

{9}:   Kurzweil, The Singularity is Near](https://www.amazon.com/gp/product/0143037889/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0143037889&linkCode=as2&tag=wabuwh00-20&linkId=54Q62R5PYJBEENTP), 118

{10}:  Bostrom, [Superintelligence: Paths, Dangers, Strategies](https://www.amazon.com/gp/product/0199678111/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0199678111&linkCode=as2&tag=wabuwh00-20&linkId=LBOTX2G2R72P5EUA), loc. 1500-1576

&nbsp